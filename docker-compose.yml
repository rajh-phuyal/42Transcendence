version: "3.8"

# This is the configuration for all docker services we use to stay:
# BARELY ALIVE

services:
  db:
    container_name: db
    image: db:latest
    build:
      context: ./Database/Postgres
      dockerfile: postgres.dockerfile
    environment:
      DB_NAME : $DB_NAME
      POSTGRES_USER : $DB_USER      #POSTGRES_USER is the default var name for the user and can not be changed
      POSTGRES_PASSWORD : $DB_PSWD  #POSTGRES_PASSWORD is the default var name for the password and can not be changed
    ports:
      - "${DB_PORT}:5432"
    volumes:
      - db-volume:/var/lib/postgresql/data
    #restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U $DB_USER -d $DB_NAME"]
      interval: 10s
      timeout: 5s
      retries: 5

  pa:
    container_name: pa
    image: pa:latest
    build:
      context: ./Database/PgAdmin
      dockerfile: pgadmin.dockerfile
      args:
        PA_DB_NAME : $PA_DB_NAME
        PA_DB_PORT : $PA_DB_PORT
        PA_DB_USER : $PA_DB_USER
        PA_DB_PSWD : $PA_DB_PSWD
    depends_on:
      db:
        condition: service_healthy
    environment:
      PGADMIN_DEFAULT_EMAIL : $PA_MAIL
      PGADMIN_DEFAULT_PASSWORD : $PA_PSWD
    ports:
      - "1234:80"
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:80/ || exit 1"] #PORT 80 is correct since it is the port of the container not the exposed port
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 10s

  be:
    container_name: be
    image: be:latest
    build:
      context: ./Backend
      dockerfile: django.dockerfile
    depends_on:
      db:
        condition: service_healthy
    environment:
      - BE_DB_HOST=db
      - BE_DB_PORT=$BE_DB_PORT
      - BE_DB_NAME=$BE_DB_NAME
      - BE_DB_USER=$BE_DB_USER
      - BE_DB_PSWD=$BE_DB_PSWD
      - BE_SECRET_KEY=$BE_SECRET_KEY
      - DJANGO_SETTINGS_MODULE=app.settings
    ports:
      - "8000:8000" #need to be changed. remove it after
    volumes:
      - ./Backend/src:/app
    restart: unless-stopped
    # [astein] CHAT GPT told me that this is a good way to check if the service is healthy
    # not sure what it means but u need to create a Health Check Endpoint
    # u think its a good idea?
    healthcheck:
      test: ["CMD-SHELL", "curl --silent --fail http://localhost:8000/health/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
    command: daphne -b 0.0.0.0 -p 8000 app.asgi:application  # astein: we need daphne to run the asgi server


  fe:
    container_name: fe
    image: fe:latest
    build:
      context: ./Frontend
      dockerfile: nginx.dockerfile
    depends_on:
      - be
      # TODO: Uncomment the line below as soon as the backend healthcheck is implemented!
      #be:
        #condition: service_healthy
    #environment:
    #  - name=value
    ports:
      - "443:443" #Maybe need to change later 443
    volumes:
      # TODO
      # ----
      # All those mount points are usefull for development sincee we dont
      # have to restart the container if we do small changes.
      # For delivery we should have entrypoint-script which will be called
      # by the dockerfile to copy all those files (if not already there) to
      # the fe-volume.
      #
      # To make the ssl more secure we do not mount the certificate at all
      # we copy and conif it as a first step in the dockerfile
      - ./Frontend/html:/usr/share/nginx/html
      - ./Frontend/css:/usr/share/nginx/css
      - ./Frontend/js:/usr/share/nginx/js
      - ./Frontend/assets:/usr/share/nginx/assets
      - ./Frontend/nginx.conf:/etc/nginx/nginx.conf
      #- ./Frontend/openssl:/etc/nginx/ssl
    restart: unless-stopped
    # TODO: revise it the healthceck is good enough...
    healthcheck:
      test: ["CMD-SHELL", "curl --silent --fail http://localhost:80/ || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

networks:
  default:
    name: $DOCKER_NETWORK
    driver: bridge

# TODO
# HERE WE CONFIGURE THE VOLUME BEFORE DELIVERING
volumes:
  db-volume:
    name: db-volume
    driver_opts:
      type: none
      device: ${VOLUME_ROOT_PATH}db-volume/ #This will be auto updated via deploy.sh!
      o: bind
#name: fe-volume
#    driver_opts:
#      type: none
#      device: /home/...
#      o: bind
